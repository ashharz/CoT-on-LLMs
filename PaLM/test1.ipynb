{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "radhe radhe\n"
     ]
    }
   ],
   "source": [
    "print('radhe radhe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting datasets\n",
      "  Downloading datasets-2.18.0-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\sk731\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\sk731\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (1.24.3)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in c:\\users\\sk731\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (15.0.0)\n",
      "Collecting pyarrow-hotfix (from datasets)\n",
      "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\sk731\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (2.2.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\sk731\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\sk731\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (4.66.2)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.4.1-cp311-cp311-win_amd64.whl.metadata (12 kB)\n",
      "Collecting multiprocess (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in c:\\users\\sk731\\appdata\\roaming\\python\\python311\\site-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets) (2024.2.0)\n",
      "Collecting aiohttp (from datasets)\n",
      "  Downloading aiohttp-3.9.3-cp311-cp311-win_amd64.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in c:\\users\\sk731\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (0.21.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\sk731\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\sk731\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (6.0.1)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\sk731\\appdata\\roaming\\python\\python311\\site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
      "  Downloading frozenlist-1.4.1-cp311-cp311-win_amd64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
      "  Downloading multidict-6.0.5-cp311-cp311-win_amd64.whl.metadata (4.3 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp->datasets)\n",
      "  Downloading yarl-1.9.4-cp311-cp311-win_amd64.whl.metadata (32 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\sk731\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub>=0.19.4->datasets) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sk731\\appdata\\roaming\\python\\python311\\site-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sk731\\appdata\\roaming\\python\\python311\\site-packages (from requests>=2.19.0->datasets) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sk731\\appdata\\roaming\\python\\python311\\site-packages (from requests>=2.19.0->datasets) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sk731\\appdata\\roaming\\python\\python311\\site-packages (from requests>=2.19.0->datasets) (2023.11.17)\n",
      "Requirement already satisfied: colorama in c:\\users\\sk731\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>=4.62.1->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\sk731\\appdata\\roaming\\python\\python311\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sk731\\appdata\\roaming\\python\\python311\\site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\sk731\\appdata\\roaming\\python\\python311\\site-packages (from pandas->datasets) (2023.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sk731\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Downloading datasets-2.18.0-py3-none-any.whl (510 kB)\n",
      "   ---------------------------------------- 0.0/510.5 kB ? eta -:--:--\n",
      "   -- ------------------------------------ 30.7/510.5 kB 640.0 kB/s eta 0:00:01\n",
      "   -- ------------------------------------ 30.7/510.5 kB 640.0 kB/s eta 0:00:01\n",
      "   --- ----------------------------------- 41.0/510.5 kB 326.8 kB/s eta 0:00:02\n",
      "   ---- ---------------------------------- 61.4/510.5 kB 363.1 kB/s eta 0:00:02\n",
      "   ---- ---------------------------------- 61.4/510.5 kB 363.1 kB/s eta 0:00:02\n",
      "   ------- ------------------------------- 92.2/510.5 kB 403.5 kB/s eta 0:00:02\n",
      "   ------- ------------------------------- 92.2/510.5 kB 403.5 kB/s eta 0:00:02\n",
      "   ------------ ------------------------- 163.8/510.5 kB 517.2 kB/s eta 0:00:01\n",
      "   ------------ ------------------------- 163.8/510.5 kB 517.2 kB/s eta 0:00:01\n",
      "   ------------ ------------------------- 163.8/510.5 kB 517.2 kB/s eta 0:00:01\n",
      "   ------------ ------------------------- 163.8/510.5 kB 517.2 kB/s eta 0:00:01\n",
      "   ------------ ------------------------- 163.8/510.5 kB 517.2 kB/s eta 0:00:01\n",
      "   ---------------- --------------------- 225.3/510.5 kB 416.7 kB/s eta 0:00:01\n",
      "   ---------------- --------------------- 225.3/510.5 kB 416.7 kB/s eta 0:00:01\n",
      "   --------------------- ---------------- 286.7/510.5 kB 453.2 kB/s eta 0:00:01\n",
      "   --------------------------- ---------- 368.6/510.5 kB 533.3 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 491.5/510.5 kB 684.6 kB/s eta 0:00:01\n",
      "   -------------------------------------- 510.5/510.5 kB 695.8 kB/s eta 0:00:00\n",
      "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "   ---------------------------------------- 0.0/116.3 kB ? eta -:--:--\n",
      "   ---------- ----------------------------- 30.7/116.3 kB 1.3 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 30.7/116.3 kB 1.3 MB/s eta 0:00:01\n",
      "   -------------------- ------------------ 61.4/116.3 kB 465.5 kB/s eta 0:00:01\n",
      "   ------------------------------ -------- 92.2/116.3 kB 525.1 kB/s eta 0:00:01\n",
      "   -------------------------------------- 116.3/116.3 kB 522.2 kB/s eta 0:00:00\n",
      "Downloading aiohttp-3.9.3-cp311-cp311-win_amd64.whl (365 kB)\n",
      "   ---------------------------------------- 0.0/365.3 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/365.3 kB ? eta -:--:--\n",
      "   --- ----------------------------------- 30.7/365.3 kB 330.3 kB/s eta 0:00:02\n",
      "   --- ----------------------------------- 30.7/365.3 kB 330.3 kB/s eta 0:00:02\n",
      "   ---- ---------------------------------- 41.0/365.3 kB 219.4 kB/s eta 0:00:02\n",
      "   ------ -------------------------------- 61.4/365.3 kB 328.2 kB/s eta 0:00:01\n",
      "   ------ -------------------------------- 61.4/365.3 kB 328.2 kB/s eta 0:00:01\n",
      "   ------ -------------------------------- 61.4/365.3 kB 328.2 kB/s eta 0:00:01\n",
      "   ------- ------------------------------- 71.7/365.3 kB 187.3 kB/s eta 0:00:02\n",
      "   ----------- -------------------------- 112.6/365.3 kB 273.1 kB/s eta 0:00:01\n",
      "   ------------ ------------------------- 122.9/365.3 kB 277.4 kB/s eta 0:00:01\n",
      "   -------------- ----------------------- 143.4/365.3 kB 315.4 kB/s eta 0:00:01\n",
      "   -------------- ----------------------- 143.4/365.3 kB 315.4 kB/s eta 0:00:01\n",
      "   -------------- ----------------------- 143.4/365.3 kB 315.4 kB/s eta 0:00:01\n",
      "   -------------- ----------------------- 143.4/365.3 kB 315.4 kB/s eta 0:00:01\n",
      "   -------------- ----------------------- 143.4/365.3 kB 315.4 kB/s eta 0:00:01\n",
      "   -------------- ----------------------- 143.4/365.3 kB 315.4 kB/s eta 0:00:01\n",
      "   --------------- ---------------------- 153.6/365.3 kB 199.7 kB/s eta 0:00:02\n",
      "   ------------------ ------------------- 174.1/365.3 kB 209.8 kB/s eta 0:00:01\n",
      "   -------------------- ----------------- 194.6/365.3 kB 227.0 kB/s eta 0:00:01\n",
      "   ------------------------ ------------- 235.5/365.3 kB 262.3 kB/s eta 0:00:01\n",
      "   ---------------------------------- --- 327.7/365.3 kB 350.4 kB/s eta 0:00:01\n",
      "   -------------------------------------- 365.3/365.3 kB 379.0 kB/s eta 0:00:00\n",
      "Downloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
      "   ---------------------------------------- 0.0/143.5 kB ? eta -:--:--\n",
      "   ---------------------------- ----------- 102.4/143.5 kB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 143.5/143.5 kB 2.1 MB/s eta 0:00:00\n",
      "Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
      "Downloading xxhash-3.4.1-cp311-cp311-win_amd64.whl (29 kB)\n",
      "Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading frozenlist-1.4.1-cp311-cp311-win_amd64.whl (50 kB)\n",
      "   ---------------------------------------- 0.0/50.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 50.5/50.5 kB ? eta 0:00:00\n",
      "Downloading multidict-6.0.5-cp311-cp311-win_amd64.whl (28 kB)\n",
      "Downloading yarl-1.9.4-cp311-cp311-win_amd64.whl (76 kB)\n",
      "   ---------------------------------------- 0.0/76.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 76.7/76.7 kB 4.2 MB/s eta 0:00:00\n",
      "Installing collected packages: xxhash, pyarrow-hotfix, multidict, frozenlist, dill, yarl, multiprocess, aiosignal, aiohttp, datasets\n",
      "Successfully installed aiohttp-3.9.3 aiosignal-1.3.1 datasets-2.18.0 dill-0.3.8 frozenlist-1.4.1 multidict-6.0.5 multiprocess-0.70.16 pyarrow-hotfix-0.6 xxhash-3.4.1 yarl-1.9.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 2.31M/2.31M [00:02<00:00, 928kB/s]\n",
      "Downloading data: 100%|██████████| 419k/419k [00:00<00:00, 795kB/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2c6c53de19b48f1b641ec3dbe170292",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/7473 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "486a38e461d84b01ad63d1eec4045d29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1319 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datasets\n",
    "gsm8k = datasets.load_dataset('gsm8k','main')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1319\n"
     ]
    }
   ],
   "source": [
    "print(len(gsm8k['test']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file exported successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Convert the dataset to a pandas DataFrame\n",
    "df = pd.DataFrame(gsm8k['test'])  \n",
    "\n",
    "# Export the DataFrame to a CSV file\n",
    "df.to_csv('gsm8k_test1.csv', index=False)  \n",
    "\n",
    "print(\"CSV file exported successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In test set we have total 1319 tets examples of question as well as their detailed answer.But due to the limitation of compuatation power we will randomly sample only 200 examples for our model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly selected 200 rows written to 'gsm8k_test.csv' successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Read the original CSV file into a pandas DataFrame\n",
    "df = pd.read_csv('gsm8k_test1.csv')\n",
    "\n",
    "# Randomly select 200 rows from the DataFrame\n",
    "random_indices = random.sample(range(len(df)), 200)\n",
    "df_selected = df.iloc[random_indices]\n",
    "\n",
    "# Write the selected rows to a new CSV file named 'gsm8k_test.csv'\n",
    "df_selected.to_csv('gsm8k_test.csv', index=False)\n",
    "\n",
    "print(\"Randomly selected 200 rows written to 'gsm8k_test.csv' successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ali has four $10 bills and six $20 bills that ...</td>\n",
       "      <td>Four $10 bills have a value of 4*$10 =$&lt;&lt;4*10=...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shiela bought five cell phones for $150 each f...</td>\n",
       "      <td>A $150 x 2/100 = $&lt;&lt;150*2/100=3&gt;&gt;3 interest wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rita hand-picks Junebugs off of her plants eve...</td>\n",
       "      <td>On both Tuesday and Wednesday, she removed twi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>While at the dollar store, Sloane counts 100 c...</td>\n",
       "      <td>On the second day, she counted 100+50 = &lt;&lt;100+...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Three friends: Mike, Jim, and Tony decided to ...</td>\n",
       "      <td>After 3 rounds Jim has 21 points - 3 points = ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  Ali has four $10 bills and six $20 bills that ...   \n",
       "1  Shiela bought five cell phones for $150 each f...   \n",
       "2  Rita hand-picks Junebugs off of her plants eve...   \n",
       "3  While at the dollar store, Sloane counts 100 c...   \n",
       "4  Three friends: Mike, Jim, and Tony decided to ...   \n",
       "\n",
       "                                              answer  \n",
       "0  Four $10 bills have a value of 4*$10 =$<<4*10=...  \n",
       "1  A $150 x 2/100 = $<<150*2/100=3>>3 interest wi...  \n",
       "2  On both Tuesday and Wednesday, she removed twi...  \n",
       "3  On the second day, she counted 100+50 = <<100+...  \n",
       "4  After 3 rounds Jim has 21 points - 3 points = ...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('gsm8k_test.csv')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as palm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "palm.configure(api_key=\"AIzaSyCV6bQxB4C4HD2AjaBfyKJOiEX8ZTw8Ggg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name: models/text-bison-001\n"
     ]
    }
   ],
   "source": [
    "models=[m for m in palm.list_models() if \"generateText\" in m.supported_generation_methods]\n",
    "\n",
    "for m in models:\n",
    "    print(f\"Model Name: {m.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'models/text-bison-001'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=models[0].name\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Let's start to experiment with our GSM8K data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8-Shot Example with CoT prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text file 'evaluation_PaLM.txt' created successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "# Open the text file in write mode\n",
    "with open('evaluation_PaLM.txt', 'w',encoding=\"utf-8\") as file:\n",
    "    # Iterate over each row in the DataFrame\n",
    "    for index, row in df.iterrows():\n",
    "        question = row['question']\n",
    "        answer = row['answer']\n",
    "        prompt=f'''\n",
    "        After looking at the following 8 questions and their detailed answers  , write a step-by-step explanation on how to solve the 9th question:\n",
    "        Question1: \"There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there will be 21 trees. How many trees did the grove workers plant today?\"\n",
    "        Answer: \"There are 15 trees originally. Then there were 21 trees after some more were planted. So there must have been 21 - 15 = 6. The answer is 6.\"\n",
    "        Question2: \"If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\"\n",
    "        Answer: \"There are originally 3 cars. 2 more cars arrive. 3 + 2 = 5. The answer is 5.\"\n",
    "        Question3: \"Leah had 32 chocolates and her sister had 42. If they ate 35, how many pieces do they have left in total?\"\n",
    "        Answer: \"Originally, Leah had 32 chocolates. Her sister had 42. So in total they had 32 + 42 = 74. After eating 35, they had 74 - 35 = 39. The answer is 39.\"\n",
    "        Question4: \"Jason had 20 lollipops. He gave Denny some lollipops. Now Jason has 12 lollipops. How many lollipops did Jason give to Denny?\"\n",
    "        Answer: \"Jason started with 20 lollipops. Then he had 12 after giving some to Denny. So he gave Denny 20 - 12 = 8. The answer is 8.\"\n",
    "        Question5: \"Shawn has five toys. For Christmas, he got two toys each from his mom and dad. How many toys does he have now?\"\n",
    "        Answer: \"Shawn started with 5 toys. If he got 2 toys each from his mom and dad, then that is 4 more toys. 5 + 4 = 9.The answer is 9.\"\n",
    "        Question6: \"There were nine computers in the server room. Five more computers were installed each day, from monday to thursday. How many computers are now in the server room?\"\n",
    "        Answer: \"There were originally 9 computers. For each of 4 days, 5 more computers were added. So 5 * 4 = 20 computers were added. 9 + 20 is 29. The answer is 29.\"\n",
    "        Question7: \"Michael had 58 golf balls. On tuesday, he lost 23 golf balls. On wednesday, he lost 2 more. How many golf balls did he have at the end of wednesday?\"\n",
    "        Answer: \"Michael started with 58 golf balls. After losing 23 on tuesday, he had 58 - 23 = 35. After losing 2 more, he had 35 - 2 = 33 golf balls. The answer is 33.\"\n",
    "        Question8: \"Olivia has $23. She bought five bagels for $3 each. How much money does she have left?\"\n",
    "        Answer: \"Olivia had 23 dollars. 5 bagels for 3 dollars each will be 5 x 3 = 15 dollars. So she has 23 - 15 dollars left. 23- 15 is 8. The answer is 8.\"\n",
    "        Question9: {question}\n",
    "        '''\n",
    "        completion=palm.generate_text(model=model,prompt=prompt,temperature=0.5,max_output_tokens=1024)\n",
    "        model_answer=completion.result\n",
    "        # Write the question and the new answer to the text file\n",
    "        file.write(f\"QUESTION: {question}\\n***********************************\\nANSWER: {answer}\\n**********************************\\nMODEL's_ANSWER: {model_answer}\\n##############################################################################################\\n\")\n",
    "        \n",
    "       \n",
    "        \n",
    "   \n",
    "\n",
    "\n",
    "print(\"Text file 'evaluation_PaLM.txt' created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text file 'evaluation_PaLM_8shot_CoT.txt' created successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "# Open the text file in write mode\n",
    "with open('evaluation_PaLM_8shot_CoT.txt', 'w',encoding=\"utf-8\") as file:\n",
    "    # Iterate over each row in the DataFrame\n",
    "    for index, row in df.iterrows():\n",
    "        question = row['question']\n",
    "        answer = row['answer']\n",
    "        prompt=f'''\n",
    "        After looking at the following 8 questions and their detailed answers  , write a solution with step-by-step explanation for the 9th question:\n",
    "        Question1: \"There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there will be 21 trees. How many trees did the grove workers plant today?\"\n",
    "        Answer: \"There are 15 trees originally. Then there were 21 trees after some more were planted. So there must have been 21 - 15 = 6. The answer is 6.\"\n",
    "        Question2: \"If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\"\n",
    "        Answer: \"There are originally 3 cars. 2 more cars arrive. 3 + 2 = 5. The answer is 5.\"\n",
    "        Question3: \"Leah had 32 chocolates and her sister had 42. If they ate 35, how many pieces do they have left in total?\"\n",
    "        Answer: \"Originally, Leah had 32 chocolates. Her sister had 42. So in total they had 32 + 42 = 74. After eating 35, they had 74 - 35 = 39. The answer is 39.\"\n",
    "        Question4: \"Jason had 20 lollipops. He gave Denny some lollipops. Now Jason has 12 lollipops. How many lollipops did Jason give to Denny?\"\n",
    "        Answer: \"Jason started with 20 lollipops. Then he had 12 after giving some to Denny. So he gave Denny 20 - 12 = 8. The answer is 8.\"\n",
    "        Question5: \"Shawn has five toys. For Christmas, he got two toys each from his mom and dad. How many toys does he have now?\"\n",
    "        Answer: \"Shawn started with 5 toys. If he got 2 toys each from his mom and dad, then that is 4 more toys. 5 + 4 = 9.The answer is 9.\"\n",
    "        Question6: \"There were nine computers in the server room. Five more computers were installed each day, from monday to thursday. How many computers are now in the server room?\"\n",
    "        Answer: \"There were originally 9 computers. For each of 4 days, 5 more computers were added. So 5 * 4 = 20 computers were added. 9 + 20 is 29. The answer is 29.\"\n",
    "        Question7: \"Michael had 58 golf balls. On tuesday, he lost 23 golf balls. On wednesday, he lost 2 more. How many golf balls did he have at the end of wednesday?\"\n",
    "        Answer: \"Michael started with 58 golf balls. After losing 23 on tuesday, he had 58 - 23 = 35. After losing 2 more, he had 35 - 2 = 33 golf balls. The answer is 33.\"\n",
    "        Question8: \"Olivia has $23. She bought five bagels for $3 each. How much money does she have left?\"\n",
    "        Answer: \"Olivia had 23 dollars. 5 bagels for 3 dollars each will be 5 x 3 = 15 dollars. So she has 23 - 15 dollars left. 23- 15 is 8. The answer is 8.\"\n",
    "        Question9: {question}\n",
    "        '''\n",
    "        completion=palm.generate_text(model=model,prompt=prompt,temperature=0.5,max_output_tokens=1024)\n",
    "        model_answer=completion.result\n",
    "        # Write the question and the new answer to the text file\n",
    "        file.write(f\"QUESTION: {question}\\n***********************************\\nANSWER: {answer}\\n**********************************\\nMODEL's_ANSWER: {model_answer}\\n##############################################################################################\\n\")\n",
    "        \n",
    "       \n",
    "        \n",
    "   \n",
    "\n",
    "\n",
    "print(\"Text file 'evaluation_PaLM_8shot_CoT.txt' created successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 Shot Example of CoT prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalServerError",
     "evalue": "500 An internal error has occurred. Please retry or report in https://developers.generativeai.google/guide/troubleshooting",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalServerError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 26\u001b[0m\n\u001b[0;32m      6\u001b[0m answer \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manswer\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      7\u001b[0m prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'''\u001b[39m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124mAfter looking at the following 7 questions and their detailed answers, write a solution with step-by-step explanation for the 8th question:\u001b[39m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;124mQuestion1: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThere are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there will be 21 trees. How many trees did the grove workers plant today?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;124mQuestion8: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquestion\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;124m'''\u001b[39m\n\u001b[1;32m---> 26\u001b[0m completion\u001b[38;5;241m=\u001b[39m\u001b[43mpalm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mmax_output_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m model_answer\u001b[38;5;241m=\u001b[39mcompletion\u001b[38;5;241m.\u001b[39mresult\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Write the question and the new answer to the text file\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\google\\generativeai\\text.py:202\u001b[0m, in \u001b[0;36mgenerate_text\u001b[1;34m(model, prompt, temperature, candidate_count, max_output_tokens, top_p, top_k, safety_settings, stop_sequences, client, request_options)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Calls the API and returns a `types.Completion` containing the response.\u001b[39;00m\n\u001b[0;32m    147\u001b[0m \n\u001b[0;32m    148\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;124;03m    A `types.Completion` containing the model's text completion response.\u001b[39;00m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    190\u001b[0m request \u001b[38;5;241m=\u001b[39m _make_generate_text_request(\n\u001b[0;32m    191\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m    192\u001b[0m     prompt\u001b[38;5;241m=\u001b[39mprompt,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    199\u001b[0m     stop_sequences\u001b[38;5;241m=\u001b[39mstop_sequences,\n\u001b[0;32m    200\u001b[0m )\n\u001b[1;32m--> 202\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_generate_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_options\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\google\\generativeai\\text.py:240\u001b[0m, in \u001b[0;36m_generate_response\u001b[1;34m(request, client, request_options)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m client \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    238\u001b[0m     client \u001b[38;5;241m=\u001b[39m get_default_text_client()\n\u001b[1;32m--> 240\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrequest_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    241\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(response)\u001b[38;5;241m.\u001b[39mto_dict(response)\n\u001b[0;32m    243\u001b[0m response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilters\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m safety_types\u001b[38;5;241m.\u001b[39mconvert_filters_to_enums(response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilters\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\google\\ai\\generativelanguage_v1beta\\services\\text_service\\client.py:648\u001b[0m, in \u001b[0;36mTextServiceClient.generate_text\u001b[1;34m(self, request, model, prompt, temperature, candidate_count, max_output_tokens, top_p, top_k, retry, timeout, metadata)\u001b[0m\n\u001b[0;32m    643\u001b[0m metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(metadata) \u001b[38;5;241m+\u001b[39m (\n\u001b[0;32m    644\u001b[0m     gapic_v1\u001b[38;5;241m.\u001b[39mrouting_header\u001b[38;5;241m.\u001b[39mto_grpc_metadata(((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, request\u001b[38;5;241m.\u001b[39mmodel),)),\n\u001b[0;32m    645\u001b[0m )\n\u001b[0;32m    647\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[1;32m--> 648\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    649\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    650\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    651\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    652\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    653\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    655\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[0;32m    656\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\google\\api_core\\gapic_v1\\method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[1;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[1;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\google\\api_core\\retry\\retry_unary.py:293\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    289\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    290\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[0;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[0;32m    292\u001b[0m )\n\u001b[1;32m--> 293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    299\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\google\\api_core\\retry\\retry_unary.py:153\u001b[0m, in \u001b[0;36mretry_target\u001b[1;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[1;32m--> 153\u001b[0m     \u001b[43m_retry_error_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43msleep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexception_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(sleep)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\google\\api_core\\retry\\retry_base.py:212\u001b[0m, in \u001b[0;36m_retry_error_helper\u001b[1;34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predicate_fn(exc):\n\u001b[0;32m    207\u001b[0m     final_exc, source_exc \u001b[38;5;241m=\u001b[39m exc_factory_fn(\n\u001b[0;32m    208\u001b[0m         error_list,\n\u001b[0;32m    209\u001b[0m         RetryFailureReason\u001b[38;5;241m.\u001b[39mNON_RETRYABLE_ERROR,\n\u001b[0;32m    210\u001b[0m         original_timeout,\n\u001b[0;32m    211\u001b[0m     )\n\u001b[1;32m--> 212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msource_exc\u001b[39;00m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    214\u001b[0m     on_error_fn(exc)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\google\\api_core\\retry\\retry_unary.py:144\u001b[0m, in \u001b[0;36mretry_target\u001b[1;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 144\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    145\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n\u001b[0;32m    146\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(_ASYNC_RETRY_WARNING)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\google\\api_core\\timeout.py:120\u001b[0m, in \u001b[0;36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;66;03m# Avoid setting negative timeout\u001b[39;00m\n\u001b[0;32m    118\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout \u001b[38;5;241m-\u001b[39m time_since_first_attempt)\n\u001b[1;32m--> 120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\google\\api_core\\grpc_helpers.py:78\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m---> 78\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[1;31mInternalServerError\u001b[0m: 500 An internal error has occurred. Please retry or report in https://developers.generativeai.google/guide/troubleshooting"
     ]
    }
   ],
   "source": [
    "# Open the text file in write mode\n",
    "with open('evaluation_PaLM_7shot_CoT.txt', 'w',encoding=\"utf-8\") as file:\n",
    "    # Iterate over each row in the DataFrame\n",
    "    for index, row in df.iterrows():\n",
    "        question = row['question']\n",
    "        answer = row['answer']\n",
    "        prompt=f'''\n",
    "        After looking at the following 7 questions and their detailed answers, write a solution with step-by-step explanation for the 8th question:\n",
    "        Question1: \"There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there will be 21 trees. How many trees did the grove workers plant today?\"\n",
    "        Answer: \"There are 15 trees originally. Then there were 21 trees after some more were planted. So there must have been 21 - 15 = 6. The answer is 6.\"\n",
    "        Question2: \"If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\"\n",
    "        Answer: \"There are originally 3 cars. 2 more cars arrive. 3 + 2 = 5. The answer is 5.\"\n",
    "        Question3: \"Leah had 32 chocolates and her sister had 42. If they ate 35, how many pieces do they have left in total?\"\n",
    "        Answer: \"Originally, Leah had 32 chocolates. Her sister had 42. So in total they had 32 + 42 = 74. After eating 35, they had 74 - 35 = 39. The answer is 39.\"\n",
    "        Question4: \"Jason had 20 lollipops. He gave Denny some lollipops. Now Jason has 12 lollipops. How many lollipops did Jason give to Denny?\"\n",
    "        Answer: \"Jason started with 20 lollipops. Then he had 12 after giving some to Denny. So he gave Denny 20 - 12 = 8. The answer is 8.\"\n",
    "        Question5: \"Shawn has five toys. For Christmas, he got two toys each from his mom and dad. How many toys does he have now?\"\n",
    "        Answer: \"Shawn started with 5 toys. If he got 2 toys each from his mom and dad, then that is 4 more toys. 5 + 4 = 9.The answer is 9.\"\n",
    "        Question6: \"There were nine computers in the server room. Five more computers were installed each day, from monday to thursday. How many computers are now in the server room?\"\n",
    "        Answer: \"There were originally 9 computers. For each of 4 days, 5 more computers were added. So 5 * 4 = 20 computers were added. 9 + 20 is 29. The answer is 29.\"\n",
    "        Question7: \"Michael had 58 golf balls. On tuesday, he lost 23 golf balls. On wednesday, he lost 2 more. How many golf balls did he have at the end of wednesday?\"\n",
    "        Answer: \"Michael started with 58 golf balls. After losing 23 on tuesday, he had 58 - 23 = 35. After losing 2 more, he had 35 - 2 = 33 golf balls. The answer is 33.\"\n",
    "\n",
    "        Question8: {question}\n",
    "        '''\n",
    "        completion=palm.generate_text(model=model,prompt=prompt,temperature=0.5,max_output_tokens=1024)\n",
    "        model_answer=completion.result\n",
    "        # Write the question and the new answer to the text file\n",
    "        file.write(f\"QUESTION: {question}\\n***********************************\\nANSWER: {answer}\\n**********************************\\nMODEL's_ANSWER: {model_answer}\\n##############################################################################################\\n\")\n",
    "        \n",
    "       \n",
    "        \n",
    "   \n",
    "\n",
    "\n",
    "print(\"evaluation_PaLM_7shot_CoT.txt' created successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 Shot CoT Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the text file in write mode\n",
    "with open('evaluation_PaLM_6shot_CoT.txt', 'w',encoding=\"utf-8\") as file:\n",
    "    # Iterate over each row in the DataFrame\n",
    "    for index, row in df.iterrows():\n",
    "        question = row['question']\n",
    "        answer = row['answer']\n",
    "        prompt=f'''\n",
    "        After looking at the following 6 questions and their detailed answers  , write a solution with step-by-step explanation for the 7th question:\n",
    "        Question1: \"There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there will be 21 trees. How many trees did the grove workers plant today?\"\n",
    "        Answer: \"There are 15 trees originally. Then there were 21 trees after some more were planted. So there must have been 21 - 15 = 6. The answer is 6.\"\n",
    "        Question2: \"If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\"\n",
    "        Answer: \"There are originally 3 cars. 2 more cars arrive. 3 + 2 = 5. The answer is 5.\"\n",
    "        Question3: \"Leah had 32 chocolates and her sister had 42. If they ate 35, how many pieces do they have left in total?\"\n",
    "        Answer: \"Originally, Leah had 32 chocolates. Her sister had 42. So in total they had 32 + 42 = 74. After eating 35, they had 74 - 35 = 39. The answer is 39.\"\n",
    "        Question4: \"Jason had 20 lollipops. He gave Denny some lollipops. Now Jason has 12 lollipops. How many lollipops did Jason give to Denny?\"\n",
    "        Answer: \"Jason started with 20 lollipops. Then he had 12 after giving some to Denny. So he gave Denny 20 - 12 = 8. The answer is 8.\"\n",
    "        Question5: \"Shawn has five toys. For Christmas, he got two toys each from his mom and dad. How many toys does he have now?\"\n",
    "        Answer: \"Shawn started with 5 toys. If he got 2 toys each from his mom and dad, then that is 4 more toys. 5 + 4 = 9.The answer is 9.\"\n",
    "        Question6: \"There were nine computers in the server room. Five more computers were installed each day, from monday to thursday. How many computers are now in the server room?\"\n",
    "        Answer: \"There were originally 9 computers. For each of 4 days, 5 more computers were added. So 5 * 4 = 20 computers were added. 9 + 20 is 29. The answer is 29.\"\n",
    "\n",
    "        Question7: {question}\n",
    "        '''\n",
    "        completion=palm.generate_text(model=model,prompt=prompt,temperature=0.5,max_output_tokens=1024)\n",
    "        model_answer=completion.result\n",
    "        # Write the question and the new answer to the text file\n",
    "        file.write(f\"QUESTION: {question}\\n***********************************\\nANSWER: {answer}\\n**********************************\\nMODEL's_ANSWER: {model_answer}\\n##############################################################################################\\n\")\n",
    "        \n",
    "       \n",
    "        \n",
    "   \n",
    "\n",
    "\n",
    "print(\"evaluation_PaLM_6shot_CoT.txt' created successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 shot CoT example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the text file in write mode\n",
    "with open('evaluation_PaLM_5shot_CoT.txt', 'w',encoding=\"utf-8\") as file:\n",
    "    # Iterate over each row in the DataFrame\n",
    "    for index, row in df.iterrows():\n",
    "        question = row['question']\n",
    "        answer = row['answer']\n",
    "        prompt=f'''\n",
    "        After looking at the following 5 questions and their detailed answers  , write a solution with step-by-step explanation for the 6th question:\n",
    "        Question1: \"There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there will be 21 trees. How many trees did the grove workers plant today?\"\n",
    "        Answer: \"There are 15 trees originally. Then there were 21 trees after some more were planted. So there must have been 21 - 15 = 6. The answer is 6.\"\n",
    "        Question2: \"If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\"\n",
    "        Answer: \"There are originally 3 cars. 2 more cars arrive. 3 + 2 = 5. The answer is 5.\"\n",
    "        Question3: \"Leah had 32 chocolates and her sister had 42. If they ate 35, how many pieces do they have left in total?\"\n",
    "        Answer: \"Originally, Leah had 32 chocolates. Her sister had 42. So in total they had 32 + 42 = 74. After eating 35, they had 74 - 35 = 39. The answer is 39.\"\n",
    "        Question4: \"Jason had 20 lollipops. He gave Denny some lollipops. Now Jason has 12 lollipops. How many lollipops did Jason give to Denny?\"\n",
    "        Answer: \"Jason started with 20 lollipops. Then he had 12 after giving some to Denny. So he gave Denny 20 - 12 = 8. The answer is 8.\"\n",
    "        Question5: \"Shawn has five toys. For Christmas, he got two toys each from his mom and dad. How many toys does he have now?\"\n",
    "        Answer: \"Shawn started with 5 toys. If he got 2 toys each from his mom and dad, then that is 4 more toys. 5 + 4 = 9.The answer is 9.\"\n",
    "        Question6: {question}\n",
    "        '''\n",
    "        completion=palm.generate_text(model=model,prompt=prompt,temperature=0.5,max_output_tokens=1024)\n",
    "        model_answer=completion.result\n",
    "        # Write the question and the new answer to the text file\n",
    "        file.write(f\"QUESTION: {question}\\n***********************************\\nANSWER: {answer}\\n**********************************\\nMODEL's_ANSWER: {model_answer}\\n##############################################################################################\\n\")\n",
    "        \n",
    "       \n",
    "        \n",
    "   \n",
    "\n",
    "\n",
    "print(\"Text file 'evaluation_PaLM_5shot_CoT.txt' created successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 shot CoT Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the text file in write mode\n",
    "with open('evaluation_PaLM_4shot_CoT.txt', 'w',encoding=\"utf-8\") as file:\n",
    "    # Iterate over each row in the DataFrame\n",
    "    for index, row in df.iterrows():\n",
    "        question = row['question']\n",
    "        answer = row['answer']\n",
    "        prompt=f'''\n",
    "        After looking at the following 4 questions and their detailed answers  , write a solution with step-by-step explanation for the 5th question:\n",
    "        Question1: \"There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there will be 21 trees. How many trees did the grove workers plant today?\"\n",
    "        Answer: \"There are 15 trees originally. Then there were 21 trees after some more were planted. So there must have been 21 - 15 = 6. The answer is 6.\"\n",
    "        Question2: \"If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\"\n",
    "        Answer: \"There are originally 3 cars. 2 more cars arrive. 3 + 2 = 5. The answer is 5.\"\n",
    "        Question3: \"Leah had 32 chocolates and her sister had 42. If they ate 35, how many pieces do they have left in total?\"\n",
    "        Answer: \"Originally, Leah had 32 chocolates. Her sister had 42. So in total they had 32 + 42 = 74. After eating 35, they had 74 - 35 = 39. The answer is 39.\"\n",
    "        Question4: \"Jason had 20 lollipops. He gave Denny some lollipops. Now Jason has 12 lollipops. How many lollipops did Jason give to Denny?\"\n",
    "        Answer: \"Jason started with 20 lollipops. Then he had 12 after giving some to Denny. So he gave Denny 20 - 12 = 8. The answer is 8.\"\n",
    "\n",
    "        Question5: {question}\n",
    "        '''\n",
    "        completion=palm.generate_text(model=model,prompt=prompt,temperature=0.5,max_output_tokens=1024)\n",
    "        model_answer=completion.result\n",
    "        # Write the question and the new answer to the text file\n",
    "        file.write(f\"QUESTION: {question}\\n***********************************\\nANSWER: {answer}\\n**********************************\\nMODEL's_ANSWER: {model_answer}\\n##############################################################################################\\n\")\n",
    "        \n",
    "       \n",
    "        \n",
    "   \n",
    "\n",
    "\n",
    "print(\"Text file 'evaluation_PaLM_4shot_CoT.txt' created successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Shot CoT Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the text file in write mode\n",
    "with open('evaluation_PaLM_3shot_CoT.txt', 'w',encoding=\"utf-8\") as file:\n",
    "    # Iterate over each row in the DataFrame\n",
    "    for index, row in df.iterrows():\n",
    "        question = row['question']\n",
    "        answer = row['answer']\n",
    "        prompt=f'''\n",
    "        After looking at the following 3 questions and their detailed answers  , write a solution with step-by-step explanation for the 4th question:\n",
    "        Question1: \"There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there will be 21 trees. How many trees did the grove workers plant today?\"\n",
    "        Answer: \"There are 15 trees originally. Then there were 21 trees after some more were planted. So there must have been 21 - 15 = 6. The answer is 6.\"\n",
    "        Question2: \"If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\"\n",
    "        Answer: \"There are originally 3 cars. 2 more cars arrive. 3 + 2 = 5. The answer is 5.\"\n",
    "        Question3: \"Leah had 32 chocolates and her sister had 42. If they ate 35, how many pieces do they have left in total?\"\n",
    "        Answer: \"Originally, Leah had 32 chocolates. Her sister had 42. So in total they had 32 + 42 = 74. After eating 35, they had 74 - 35 = 39. The answer is 39.\"\n",
    "\n",
    "\n",
    "        Question4: {question}\n",
    "        '''\n",
    "        completion=palm.generate_text(model=model,prompt=prompt,temperature=0.5,max_output_tokens=1024)\n",
    "        model_answer=completion.result\n",
    "        # Write the question and the new answer to the text file\n",
    "        file.write(f\"QUESTION: {question}\\n***********************************\\nANSWER: {answer}\\n**********************************\\nMODEL's_ANSWER: {model_answer}\\n##############################################################################################\\n\")\n",
    "        \n",
    "       \n",
    "        \n",
    "   \n",
    "\n",
    "\n",
    "print(\"Text file 'evaluation_PaLM_3shot_CoT.txt' created successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Shot CoT Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the text file in write mode\n",
    "with open('evaluation_PaLM_2shot_CoT.txt', 'w',encoding=\"utf-8\") as file:\n",
    "    # Iterate over each row in the DataFrame\n",
    "    for index, row in df.iterrows():\n",
    "        question = row['question']\n",
    "        answer = row['answer']\n",
    "        prompt=f'''\n",
    "        After looking at the following 2 questions and their detailed answers  , write a solution with step-by-step explanation for the 3rd question:\n",
    "        Question1: \"There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there will be 21 trees. How many trees did the grove workers plant today?\"\n",
    "        Answer: \"There are 15 trees originally. Then there were 21 trees after some more were planted. So there must have been 21 - 15 = 6. The answer is 6.\"\n",
    "        Question2: \"If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\"\n",
    "        Answer: \"There are originally 3 cars. 2 more cars arrive. 3 + 2 = 5. The answer is 5.\"\n",
    "\n",
    "        Question3: {question}\n",
    "        '''\n",
    "        completion=palm.generate_text(model=model,prompt=prompt,temperature=0.5,max_output_tokens=1024)\n",
    "        model_answer=completion.result\n",
    "        # Write the question and the new answer to the text file\n",
    "        file.write(f\"QUESTION: {question}\\n***********************************\\nANSWER: {answer}\\n**********************************\\nMODEL's_ANSWER: {model_answer}\\n##############################################################################################\\n\")\n",
    "        \n",
    "       \n",
    "        \n",
    "   \n",
    "\n",
    "\n",
    "print(\"Text file 'evaluation_PaLM_2shot_CoT.txt' created successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 shot CoT Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the text file in write mode\n",
    "with open('evaluation_PaLM_1shot_CoT.txt', 'w',encoding=\"utf-8\") as file:\n",
    "    # Iterate over each row in the DataFrame\n",
    "    for index, row in df.iterrows():\n",
    "        question = row['question']\n",
    "        answer = row['answer']\n",
    "        prompt=f'''\n",
    "        After looking at the following 1 question and its detailed answer  , write a solution with step-by-step explanation for the 2nd question:\n",
    "        Question1: \"There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there will be 21 trees. How many trees did the grove workers plant today?\"\n",
    "        Answer: \"There are 15 trees originally. Then there were 21 trees after some more were planted. So there must have been 21 - 15 = 6. The answer is 6.\"\n",
    "\n",
    "\n",
    "        Question2: {question}\n",
    "        '''\n",
    "        completion=palm.generate_text(model=model,prompt=prompt,temperature=0.5,max_output_tokens=1024)\n",
    "        model_answer=completion.result\n",
    "        # Write the question and the new answer to the text file\n",
    "        file.write(f\"QUESTION: {question}\\n***********************************\\nANSWER: {answer}\\n**********************************\\nMODEL's_ANSWER: {model_answer}\\n##############################################################################################\\n\")\n",
    "        \n",
    "       \n",
    "        \n",
    "   \n",
    "\n",
    "\n",
    "print(\"Text file 'evaluation_PaLM_1shot_CoT.txt' created successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# O shot CoT Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the text file in write mode\n",
    "with open('evaluation_PaLM_0shot_CoT.txt', 'w',encoding=\"utf-8\") as file:\n",
    "    # Iterate over each row in the DataFrame\n",
    "    for index, row in df.iterrows():\n",
    "        question = row['question']\n",
    "        answer = row['answer']\n",
    "        prompt=f'''\n",
    "        Provide a solution of the following question with step-by-step explanation:\n",
    "\n",
    "\n",
    "        Question: {question}\n",
    "        '''\n",
    "        completion=palm.generate_text(model=model,prompt=prompt,temperature=0.5,max_output_tokens=1024)\n",
    "        model_answer=completion.result\n",
    "        # Write the question and the new answer to the text file\n",
    "        file.write(f\"QUESTION: {question}\\n***********************************\\nANSWER: {answer}\\n**********************************\\nMODEL's_ANSWER: {model_answer}\\n##############################################################################################\\n\")\n",
    "        \n",
    "       \n",
    "        \n",
    "   \n",
    "\n",
    "\n",
    "print(\"Text file 'evaluation_PaLM_0shot_CoT.txt' created successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8 shot standard prompt example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "# Open the text file in write mode\n",
    "with open('evaluation_PaLM_8shot_standardPrompt.txt', 'w',encoding=\"utf-8\") as file:\n",
    "    # Iterate over each row in the DataFrame\n",
    "    for index, row in df.iterrows():\n",
    "        question = row['question']\n",
    "        answer = row['answer']\n",
    "        prompt=f'''\n",
    "        After looking at the following 8 questions and their answers  , solve the 9th question:\n",
    "        Question1: \"There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there will be 21 trees. How many trees did the grove workers plant today?\"\n",
    "        Answer: \"The answer is 6.\"\n",
    "        Question2: \"If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\"\n",
    "        Answer: \"The answer is 5.\"\n",
    "        Question3: \"Leah had 32 chocolates and her sister had 42. If they ate 35, how many pieces do they have left in total?\"\n",
    "        Answer: \"The answer is 39.\"\n",
    "        Question4: \"Jason had 20 lollipops. He gave Denny some lollipops. Now Jason has 12 lollipops. How many lollipops did Jason give to Denny?\"\n",
    "        Answer: \"The answer is 8.\"\n",
    "        Question5: \"Shawn has five toys. For Christmas, he got two toys each from his mom and dad. How many toys does he have now?\"\n",
    "        Answer: \"The answer is 9.\"\n",
    "        Question6: \"There were nine computers in the server room. Five more computers were installed each day, from monday to thursday. How many computers are now in the server room?\"\n",
    "        Answer: \"The answer is 29.\"\n",
    "        Question7: \"Michael had 58 golf balls. On tuesday, he lost 23 golf balls. On wednesday, he lost 2 more. How many golf balls did he have at the end of wednesday?\"\n",
    "        Answer: \"The answer is 33.\"\n",
    "        Question8: \"Olivia has $23. She bought five bagels for $3 each. How much money does she have left?\"\n",
    "        Answer: \"The answer is 8.\"\n",
    "        Question9: {question}\n",
    "        '''\n",
    "        completion=palm.generate_text(model=model,prompt=prompt,temperature=0.5,max_output_tokens=1024)\n",
    "        model_answer=completion.result\n",
    "        # Write the question and the new answer to the text file\n",
    "        file.write(f\"QUESTION: {question}\\n***********************************\\nANSWER: {answer}\\n**********************************\\nMODEL's_ANSWER: {model_answer}\\n##############################################################################################\\n\")\n",
    "        \n",
    "       \n",
    "        \n",
    "   \n",
    "\n",
    "\n",
    "print(\"Text file 'evaluation_PaLM.txt' created successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 shot Standard Prompt Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "# Open the text file in write mode\n",
    "with open('evaluation_PaLM_7shot_standardPrompt.txt', 'w',encoding=\"utf-8\") as file:\n",
    "    # Iterate over each row in the DataFrame\n",
    "    for index, row in df.iterrows():\n",
    "        question = row['question']\n",
    "        answer = row['answer']\n",
    "        prompt=f'''\n",
    "        After looking at the following 7 questions and their answers  , solve the 8th question:\n",
    "        Question1: \"There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there will be 21 trees. How many trees did the grove workers plant today?\"\n",
    "        Answer: \"The answer is 6.\"\n",
    "        Question2: \"If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\"\n",
    "        Answer: \"The answer is 5.\"\n",
    "        Question3: \"Leah had 32 chocolates and her sister had 42. If they ate 35, how many pieces do they have left in total?\"\n",
    "        Answer: \"The answer is 39.\"\n",
    "        Question4: \"Jason had 20 lollipops. He gave Denny some lollipops. Now Jason has 12 lollipops. How many lollipops did Jason give to Denny?\"\n",
    "        Answer: \"The answer is 8.\"\n",
    "        Question5: \"Shawn has five toys. For Christmas, he got two toys each from his mom and dad. How many toys does he have now?\"\n",
    "        Answer: \"The answer is 9.\"\n",
    "        Question6: \"There were nine computers in the server room. Five more computers were installed each day, from monday to thursday. How many computers are now in the server room?\"\n",
    "        Answer: \"The answer is 29.\"\n",
    "        Question7: \"Michael had 58 golf balls. On tuesday, he lost 23 golf balls. On wednesday, he lost 2 more. How many golf balls did he have at the end of wednesday?\"\n",
    "        Answer: \"The answer is 33.\"\n",
    "        Question8: {question}\n",
    "        '''\n",
    "        completion=palm.generate_text(model=model,prompt=prompt,temperature=0.5,max_output_tokens=1024)\n",
    "        model_answer=completion.result\n",
    "        # Write the question and the new answer to the text file\n",
    "        file.write(f\"QUESTION: {question}\\n***********************************\\nANSWER: {answer}\\n**********************************\\nMODEL's_ANSWER: {model_answer}\\n##############################################################################################\\n\")\n",
    "        \n",
    "       \n",
    "        \n",
    "   \n",
    "\n",
    "\n",
    "print(\"Text file 'evaluation_PaLM.txt' created successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 shot Standard Prompt Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "# Open the text file in write mode\n",
    "with open('evaluation_PaLM_6shot_standardPrompt.txt', 'w',encoding=\"utf-8\") as file:\n",
    "    # Iterate over each row in the DataFrame\n",
    "    for index, row in df.iterrows():\n",
    "        question = row['question']\n",
    "        answer = row['answer']\n",
    "        prompt=f'''\n",
    "        After looking at the following 6 questions and their answers  , solve the 7th question:\n",
    "        Question1: \"There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there will be 21 trees. How many trees did the grove workers plant today?\"\n",
    "        Answer: \"The answer is 6.\"\n",
    "        Question2: \"If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\"\n",
    "        Answer: \"The answer is 5.\"\n",
    "        Question3: \"Leah had 32 chocolates and her sister had 42. If they ate 35, how many pieces do they have left in total?\"\n",
    "        Answer: \"The answer is 39.\"\n",
    "        Question4: \"Jason had 20 lollipops. He gave Denny some lollipops. Now Jason has 12 lollipops. How many lollipops did Jason give to Denny?\"\n",
    "        Answer: \"The answer is 8.\"\n",
    "        Question5: \"Shawn has five toys. For Christmas, he got two toys each from his mom and dad. How many toys does he have now?\"\n",
    "        Answer: \"The answer is 9.\"\n",
    "        Question6: \"There were nine computers in the server room. Five more computers were installed each day, from monday to thursday. How many computers are now in the server room?\"\n",
    "        Answer: \"The answer is 29.\"\n",
    "\n",
    "        Question7: {question}\n",
    "        '''\n",
    "        completion=palm.generate_text(model=model,prompt=prompt,temperature=0.5,max_output_tokens=1024)\n",
    "        model_answer=completion.result\n",
    "        # Write the question and the new answer to the text file\n",
    "        file.write(f\"QUESTION: {question}\\n***********************************\\nANSWER: {answer}\\n**********************************\\nMODEL's_ANSWER: {model_answer}\\n##############################################################################################\\n\")\n",
    "        \n",
    "       \n",
    "        \n",
    "   \n",
    "\n",
    "\n",
    "print(\"Text file 'evaluation_PaLM.txt' created successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 shot standard prompt example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "# Open the text file in write mode\n",
    "with open('evaluation_PaLM_5shot_standardPrompt.txt', 'w',encoding=\"utf-8\") as file:\n",
    "    # Iterate over each row in the DataFrame\n",
    "    for index, row in df.iterrows():\n",
    "        question = row['question']\n",
    "        answer = row['answer']\n",
    "        prompt=f'''\n",
    "        After looking at the following 5 questions and their answers  , solve the 6th question:\n",
    "        Question1: \"There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there will be 21 trees. How many trees did the grove workers plant today?\"\n",
    "        Answer: \"The answer is 6.\"\n",
    "        Question2: \"If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\"\n",
    "        Answer: \"The answer is 5.\"\n",
    "        Question3: \"Leah had 32 chocolates and her sister had 42. If they ate 35, how many pieces do they have left in total?\"\n",
    "        Answer: \"The answer is 39.\"\n",
    "        Question4: \"Jason had 20 lollipops. He gave Denny some lollipops. Now Jason has 12 lollipops. How many lollipops did Jason give to Denny?\"\n",
    "        Answer: \"The answer is 8.\"\n",
    "        Question5: \"Shawn has five toys. For Christmas, he got two toys each from his mom and dad. How many toys does he have now?\"\n",
    "        Answer: \"The answer is 9.\"\n",
    "\n",
    "        Question6: {question}\n",
    "        '''\n",
    "        completion=palm.generate_text(model=model,prompt=prompt,temperature=0.5,max_output_tokens=1024)\n",
    "        model_answer=completion.result\n",
    "        # Write the question and the new answer to the text file\n",
    "        file.write(f\"QUESTION: {question}\\n***********************************\\nANSWER: {answer}\\n**********************************\\nMODEL's_ANSWER: {model_answer}\\n##############################################################################################\\n\")\n",
    "        \n",
    "       \n",
    "        \n",
    "   \n",
    "\n",
    "\n",
    "print(\"Text file 'evaluation_PaLM.txt' created successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 shot standard prompt example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "# Open the text file in write mode\n",
    "with open('evaluation_PaLM_4shot_standardPrompt.txt', 'w',encoding=\"utf-8\") as file:\n",
    "    # Iterate over each row in the DataFrame\n",
    "    for index, row in df.iterrows():\n",
    "        question = row['question']\n",
    "        answer = row['answer']\n",
    "        prompt=f'''\n",
    "        After looking at the following 4 questions and their answers  , solve the 5th question:\n",
    "        Question1: \"There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there will be 21 trees. How many trees did the grove workers plant today?\"\n",
    "        Answer: \"The answer is 6.\"\n",
    "        Question2: \"If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\"\n",
    "        Answer: \"The answer is 5.\"\n",
    "        Question3: \"Leah had 32 chocolates and her sister had 42. If they ate 35, how many pieces do they have left in total?\"\n",
    "        Answer: \"The answer is 39.\"\n",
    "        Question4: \"Jason had 20 lollipops. He gave Denny some lollipops. Now Jason has 12 lollipops. How many lollipops did Jason give to Denny?\"\n",
    "        Answer: \"The answer is 8.\"\n",
    "\n",
    "        Question5: {question}\n",
    "        '''\n",
    "        completion=palm.generate_text(model=model,prompt=prompt,temperature=0.5,max_output_tokens=1024)\n",
    "        model_answer=completion.result\n",
    "        # Write the question and the new answer to the text file\n",
    "        file.write(f\"QUESTION: {question}\\n***********************************\\nANSWER: {answer}\\n**********************************\\nMODEL's_ANSWER: {model_answer}\\n##############################################################################################\\n\")\n",
    "        \n",
    "       \n",
    "        \n",
    "   \n",
    "\n",
    "\n",
    "print(\"Text file 'evaluation_PaLM.txt' created successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 shot standard prompt example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "# Open the text file in write mode\n",
    "with open('evaluation_PaLM_3shot_standardPrompt.txt', 'w',encoding=\"utf-8\") as file:\n",
    "    # Iterate over each row in the DataFrame\n",
    "    for index, row in df.iterrows():\n",
    "        question = row['question']\n",
    "        answer = row['answer']\n",
    "        prompt=f'''\n",
    "        After looking at the following 3 questions and their answers  , solve the 4th question:\n",
    "        Question1: \"There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there will be 21 trees. How many trees did the grove workers plant today?\"\n",
    "        Answer: \"The answer is 6.\"\n",
    "        Question2: \"If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\"\n",
    "        Answer: \"The answer is 5.\"\n",
    "        Question3: \"Leah had 32 chocolates and her sister had 42. If they ate 35, how many pieces do they have left in total?\"\n",
    "        Answer: \"The answer is 39.\"\n",
    "\n",
    "        Question4: {question}\n",
    "        '''\n",
    "        completion=palm.generate_text(model=model,prompt=prompt,temperature=0.5,max_output_tokens=1024)\n",
    "        model_answer=completion.result\n",
    "        # Write the question and the new answer to the text file\n",
    "        file.write(f\"QUESTION: {question}\\n***********************************\\nANSWER: {answer}\\n**********************************\\nMODEL's_ANSWER: {model_answer}\\n##############################################################################################\\n\")\n",
    "        \n",
    "       \n",
    "        \n",
    "   \n",
    "\n",
    "\n",
    "print(\"Text file 'evaluation_PaLM.txt' created successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 shot standard prompt example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "# Open the text file in write mode\n",
    "with open('evaluation_PaLM_2shot_standardPrompt.txt', 'w',encoding=\"utf-8\") as file:\n",
    "    # Iterate over each row in the DataFrame\n",
    "    for index, row in df.iterrows():\n",
    "        question = row['question']\n",
    "        answer = row['answer']\n",
    "        prompt=f'''\n",
    "        After looking at the following 2 questions and their answers  , solve the 3rd question:\n",
    "        Question1: \"There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there will be 21 trees. How many trees did the grove workers plant today?\"\n",
    "        Answer: \"The answer is 6.\"\n",
    "        Question2: \"If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\"\n",
    "        Answer: \"The answer is 5.\"\n",
    "\n",
    "        Question3: {question}\n",
    "        '''\n",
    "        completion=palm.generate_text(model=model,prompt=prompt,temperature=0.5,max_output_tokens=1024)\n",
    "        model_answer=completion.result\n",
    "        # Write the question and the new answer to the text file\n",
    "        file.write(f\"QUESTION: {question}\\n***********************************\\nANSWER: {answer}\\n**********************************\\nMODEL's_ANSWER: {model_answer}\\n##############################################################################################\\n\")\n",
    "        \n",
    "       \n",
    "        \n",
    "   \n",
    "\n",
    "\n",
    "print(\"Text file 'evaluation_PaLM_2shot_standardPrompt.txt' created successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 shot standard prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "# Open the text file in write mode\n",
    "with open('evaluation_PaLM_1shot_standardPrompt.txt', 'w',encoding=\"utf-8\") as file:\n",
    "    # Iterate over each row in the DataFrame\n",
    "    for index, row in df.iterrows():\n",
    "        question = row['question']\n",
    "        answer = row['answer']\n",
    "        prompt=f'''\n",
    "        After looking at the following 1 question and its answer  , solve the 2nd question:\n",
    "        Question1: \"There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there will be 21 trees. How many trees did the grove workers plant today?\"\n",
    "        Answer: \"The answer is 6.\"\n",
    "\n",
    "\n",
    "        Question2: {question}\n",
    "        '''\n",
    "        completion=palm.generate_text(model=model,prompt=prompt,temperature=0.5,max_output_tokens=1024)\n",
    "        model_answer=completion.result\n",
    "        # Write the question and the new answer to the text file\n",
    "        file.write(f\"QUESTION: {question}\\n***********************************\\nANSWER: {answer}\\n**********************************\\nMODEL's_ANSWER: {model_answer}\\n##############################################################################################\\n\")\n",
    "        \n",
    "       \n",
    "        \n",
    "   \n",
    "\n",
    "\n",
    "print(\"Text file 'evaluation_PaLM_1shot_standardPrompt.txt' created successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero shot standsrd prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "# Open the text file in write mode\n",
    "with open('evaluation_PaLM_0shot_standardPrompt.txt', 'w',encoding=\"utf-8\") as file:\n",
    "    # Iterate over each row in the DataFrame\n",
    "    for index, row in df.iterrows():\n",
    "        question = row['question']\n",
    "        answer = row['answer']\n",
    "        prompt=f'''\n",
    "        Solve the following question:\n",
    "\n",
    "\n",
    "\n",
    "        Question1: {question}\n",
    "        '''\n",
    "        completion=palm.generate_text(model=model,prompt=prompt,temperature=0.5,max_output_tokens=1024)\n",
    "        model_answer=completion.result\n",
    "        # Write the question and the new answer to the text file\n",
    "        file.write(f\"QUESTION: {question}\\n***********************************\\nANSWER: {answer}\\n**********************************\\nMODEL's_ANSWER: {model_answer}\\n##############################################################################################\\n\")\n",
    "        \n",
    "       \n",
    "        \n",
    "   \n",
    "\n",
    "\n",
    "print(\"Text file 'evaluation_PaLM_0shot_standardPrompt.txt' created successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
